{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cb7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02dc678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-*-*-*-*-*-*-*-*-*-*-*-* Mahdi Momeni *-*-*-*-*-*-*-*-*-*-*-*-*-\n",
    "\n",
    "# Train data , x data is 3D and y data is 2D ,,,,, \n",
    "# it means when we give 3 things to nn in input it gives us 2 things in output\n",
    "# yt = y targets\n",
    "\n",
    "x = torch.rand(100,3)\n",
    "yt= torch.rand(100,2)   #Labels\n",
    "# -------------------------------------------------------------------\n",
    "# Create Model\n",
    "model = torch.nn.Linear(3 , 2)\n",
    "# model with 3D input and 2D output\n",
    "# -------------------------------------------------------------------\n",
    "# Defining the Loss\n",
    "# Loss is the difference between predicted y and real y\n",
    "loss = torch.nn.MSELoss()\n",
    "# -------------------------------------------------------------------\n",
    "# Optimizition\n",
    "# Optimizition just updates the weights and biases\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d928ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 loss :  0.6745937466621399\n",
      "--------\n",
      "epoch :  1 loss :  0.6724852919578552\n",
      "--------\n",
      "epoch :  2 loss :  0.6682838201522827\n",
      "--------\n",
      "epoch :  3 loss :  0.6620202660560608\n",
      "--------\n",
      "epoch :  4 loss :  0.6537402868270874\n",
      "--------\n",
      "epoch :  5 loss :  0.6435046195983887\n",
      "--------\n",
      "epoch :  6 loss :  0.6313883066177368\n",
      "--------\n",
      "epoch :  7 loss :  0.6174798011779785\n",
      "--------\n",
      "epoch :  8 loss :  0.6018811464309692\n",
      "--------\n",
      "epoch :  9 loss :  0.5847064256668091\n",
      "--------\n",
      "epoch :  10 loss :  0.5660815238952637\n",
      "--------\n",
      "epoch :  11 loss :  0.5461426973342896\n",
      "--------\n",
      "epoch :  12 loss :  0.5250359773635864\n",
      "--------\n",
      "epoch :  13 loss :  0.5029157996177673\n",
      "--------\n",
      "epoch :  14 loss :  0.4799440801143646\n",
      "--------\n",
      "epoch :  15 loss :  0.45628902316093445\n",
      "--------\n",
      "epoch :  16 loss :  0.43212369084358215\n",
      "--------\n",
      "epoch :  17 loss :  0.40762484073638916\n",
      "--------\n",
      "epoch :  18 loss :  0.3829718828201294\n",
      "--------\n",
      "epoch :  19 loss :  0.35834500193595886\n",
      "--------\n",
      "epoch :  20 loss :  0.33392444252967834\n",
      "--------\n",
      "epoch :  21 loss :  0.30988869071006775\n",
      "--------\n",
      "epoch :  22 loss :  0.2864135801792145\n",
      "--------\n",
      "epoch :  23 loss :  0.2636706233024597\n",
      "--------\n",
      "epoch :  24 loss :  0.2418261170387268\n",
      "--------\n",
      "epoch :  25 loss :  0.22103948891162872\n",
      "--------\n",
      "epoch :  26 loss :  0.20146262645721436\n",
      "--------\n",
      "epoch :  27 loss :  0.1832384169101715\n",
      "--------\n",
      "epoch :  28 loss :  0.16649968922138214\n",
      "--------\n",
      "epoch :  29 loss :  0.15136855840682983\n",
      "--------\n",
      "epoch :  30 loss :  0.13795512914657593\n",
      "--------\n",
      "epoch :  31 loss :  0.12635697424411774\n",
      "--------\n",
      "epoch :  32 loss :  0.1166582852602005\n",
      "--------\n",
      "epoch :  33 loss :  0.1089293584227562\n",
      "--------\n",
      "epoch :  34 loss :  0.10322588682174683\n",
      "--------\n",
      "epoch :  35 loss :  0.0995888039469719\n",
      "--------\n",
      "epoch :  36 loss :  0.0980437695980072\n",
      "--------\n",
      "epoch :  37 loss :  0.09860112518072128\n",
      "--------\n",
      "epoch :  38 loss :  0.10125572979450226\n",
      "--------\n",
      "epoch :  39 loss :  0.10598704218864441\n",
      "--------\n",
      "epoch :  40 loss :  0.11275924742221832\n",
      "--------\n",
      "epoch :  41 loss :  0.12152156978845596\n",
      "--------\n",
      "epoch :  42 loss :  0.13220857083797455\n",
      "--------\n",
      "epoch :  43 loss :  0.14474070072174072\n",
      "--------\n",
      "epoch :  44 loss :  0.15902480483055115\n",
      "--------\n",
      "epoch :  45 loss :  0.17495489120483398\n",
      "--------\n",
      "epoch :  46 loss :  0.19241289794445038\n",
      "--------\n",
      "epoch :  47 loss :  0.21126942336559296\n",
      "--------\n",
      "epoch :  48 loss :  0.23138488829135895\n",
      "--------\n",
      "epoch :  49 loss :  0.252610445022583\n",
      "--------\n",
      "epoch :  50 loss :  0.274789035320282\n",
      "--------\n",
      "epoch :  51 loss :  0.2977566421031952\n",
      "--------\n",
      "epoch :  52 loss :  0.32134342193603516\n",
      "--------\n",
      "epoch :  53 loss :  0.3453749120235443\n",
      "--------\n",
      "epoch :  54 loss :  0.3696734607219696\n",
      "--------\n",
      "epoch :  55 loss :  0.394059419631958\n",
      "--------\n",
      "epoch :  56 loss :  0.4183523952960968\n",
      "--------\n",
      "epoch :  57 loss :  0.4423728585243225\n",
      "--------\n",
      "epoch :  58 loss :  0.46594297885894775\n",
      "--------\n",
      "epoch :  59 loss :  0.48888859152793884\n",
      "--------\n",
      "epoch :  60 loss :  0.511039674282074\n",
      "--------\n",
      "epoch :  61 loss :  0.5322324633598328\n",
      "--------\n",
      "epoch :  62 loss :  0.5523097515106201\n",
      "--------\n",
      "epoch :  63 loss :  0.5711228847503662\n",
      "--------\n",
      "epoch :  64 loss :  0.5885322093963623\n",
      "--------\n",
      "epoch :  65 loss :  0.6044086217880249\n",
      "--------\n",
      "epoch :  66 loss :  0.6186341047286987\n",
      "--------\n",
      "epoch :  67 loss :  0.6311025023460388\n",
      "--------\n",
      "epoch :  68 loss :  0.6417211890220642\n",
      "--------\n",
      "epoch :  69 loss :  0.6504102945327759\n",
      "--------\n",
      "epoch :  70 loss :  0.6571049690246582\n",
      "--------\n",
      "epoch :  71 loss :  0.6617540717124939\n",
      "--------\n",
      "epoch :  72 loss :  0.6643221378326416\n",
      "--------\n",
      "epoch :  73 loss :  0.6647888422012329\n",
      "--------\n",
      "epoch :  74 loss :  0.6631489396095276\n",
      "--------\n",
      "epoch :  75 loss :  0.6594131588935852\n",
      "--------\n",
      "epoch :  76 loss :  0.653607189655304\n",
      "--------\n",
      "epoch :  77 loss :  0.6457720398902893\n",
      "--------\n",
      "epoch :  78 loss :  0.635963499546051\n",
      "--------\n",
      "epoch :  79 loss :  0.6242521405220032\n",
      "--------\n",
      "epoch :  80 loss :  0.6107221245765686\n",
      "--------\n",
      "epoch :  81 loss :  0.5954712629318237\n",
      "--------\n",
      "epoch :  82 loss :  0.5786097049713135\n",
      "--------\n",
      "epoch :  83 loss :  0.5602596998214722\n",
      "--------\n",
      "epoch :  84 loss :  0.5405542254447937\n",
      "--------\n",
      "epoch :  85 loss :  0.5196362733840942\n",
      "--------\n",
      "epoch :  86 loss :  0.4976576566696167\n",
      "--------\n",
      "epoch :  87 loss :  0.47477805614471436\n",
      "--------\n",
      "epoch :  88 loss :  0.4511638879776001\n",
      "--------\n",
      "epoch :  89 loss :  0.4269867241382599\n",
      "--------\n",
      "epoch :  90 loss :  0.40242233872413635\n",
      "--------\n",
      "epoch :  91 loss :  0.3776494562625885\n",
      "--------\n",
      "epoch :  92 loss :  0.3528481423854828\n",
      "--------\n",
      "epoch :  93 loss :  0.32819893956184387\n",
      "--------\n",
      "epoch :  94 loss :  0.3038810193538666\n",
      "--------\n",
      "epoch :  95 loss :  0.28007131814956665\n",
      "--------\n",
      "epoch :  96 loss :  0.2569429278373718\n",
      "--------\n",
      "epoch :  97 loss :  0.2346639782190323\n",
      "--------\n",
      "epoch :  98 loss :  0.21339648962020874\n",
      "--------\n",
      "epoch :  99 loss :  0.19329488277435303\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# using the nn that we created\n",
    "# yp = y predicted\n",
    "\n",
    "# now we have to train the nn for many timens......... i train it 100 times , you can train it more\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    yp = model(x)\n",
    "    loss_value = loss(yp , yt)\n",
    "    print( 'epoch : ', epoch , 'loss : ' , loss_value.item() )\n",
    "    print( '--------' )\n",
    "    # Taking the derivative relative to the loss value\n",
    "    loss_value.backward()\n",
    "    # updating the weights and biases\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71dc19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data :  tensor([[0.4616, 0.1040, 0.6658]])\n",
      "predict :  tensor([[0.7688, 0.6199]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# make a predict\n",
    "data = torch.rand(1,3)\n",
    "print('   data : ' , data)\n",
    "print(\"predict : \"  ,  model(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dacf89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
